Methodology- 
The methodology of this project involves a systematic approach to develop a predictive model for estimating compressive strength in concrete using machine learning techniques. Initially, a thorough dataset comprising concrete mix proportions, curing conditions, and corresponding compressive strength measurements is collected. Subsequently, the dataset undergoes preprocessing steps to handle missing values, normalize features, and address any potential biases, ensuring the data's suitability for modeling. Through exploratory data analysis (EDA), insights into the relationships between input variables and compressive strength are gained, employing visualization techniques like scatter plots and correlation matrices. Feature selection techniques are then applied to identify the most relevant input variables influencing compressive strength prediction. Following this, a variety of machine learning algorithms, including linear regression, support vector regression, random forest, and gradient boosting, are considered for model selection, with each algorithm evaluated based on performance metrics and dataset suitability. The chosen algorithms undergo rigorous training on the preprocessed dataset, employing techniques such as cross-validation and hyperparameter tuning to ensure robustness and prevent overfitting. Subsequently, model evaluation is conducted using metrics like mean absolute error and coefficient of determination to assess prediction accuracy and reliability. Feature importance analysis is performed to determine key factors driving compressive strength predictions, offering insights for concrete mix design optimization and construction practices. Finally, the results are interpreted, and practical recommendations are provided in a comprehensive report, contributing to advancements in predictive modeling techniques within the construction industry.


PYTHON CODE
import pandas as pd import numpy as np
import matplotlib.pyplot as plt import seaborn as sns from sklearn.model_selection import train_test_split from sklearn.ensemble import RandomForestRegressor from sklearn import metrics ts=pd.read_csv('TEST SHEET 2.csv')
ts.head() ts.isnull().sum() ts.shape ts.info print(ts.GRADE.value_counts()) ts.replace({'AGE':{'UNKNOWN':-1}},inplace=True) ts.head() ts.replace({'GRADE':{'M25':25,'M30':30,'M35':35}},inplace=True)
X = ts.drop(['STRENGTH FROM','STRENGTH TO'],axis=1)
Y = ts['STRENGTH FROM']
Z = ts['STRENGTH TO']
print(X) print(Y) print(Z) rfg=RandomForestRegressor()
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state=2) rfg.fit(X_train,Y_train) FDB=rfg.predict(X_test) from sklearn.metrics import r2_score errorscore = r2_score(Y_test, FDB) print("R squared error:", errorscore) plt.scatter(Y_test,FDB) plt.xlabel("actual data") plt.ylabel("predicted data") plt.show()
rfg1=RandomForestRegressor() rfg1.fit(X_train,Y_train) FDB22=rfg.predict(X_test) from sklearn.metrics import r2_score
errorscore = r2_score(Y_test, FDB22) print("R squared error:", errorscore) plt.scatter(Y_test,FDB) plt.xlabel("actual data") plt.ylabel("predicted data") plt.show()
grade = input("Enter Grade (M25, M30, M35): ") upv = float(input("Enter UPV: ")) rebound = float(input("Enter Rebound: ")) age = int(input("Enter Age: ")) input_data = {'GRADE': [grade], 'UPV': [upv], 'REBOUND': [rebound], 'AGE': [age]} input_df = pd.DataFrame(input_data) input_df.replace({'AGE': {'UNKNOWN': -1}}, inplace=True) input_df.replace({'GRADE': {'M25': 25, 'M30': 30, 'M35': 35}}, inplace=True) prediction_Y = rfg.predict(input_df) prediction_Z =
rfg1.predict(input_df) print("Predicted Strength From (Y):", prediction_Y) print("Predicted Strength To (Y):", prediction_Z)
